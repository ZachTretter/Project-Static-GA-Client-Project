{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DSI BOS 11 (May 2020) Project 5\n",
    "\n",
    "Alex Golden, Jungmoon Ham, Luke Podsiadlo, Zach Tretter\n",
    "\n",
    "Workbook 4 - Speech to Text Transcription\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T19:47:09.907464Z",
     "start_time": "2020-05-13T19:47:09.903512Z"
    }
   },
   "source": [
    "## Speech Recognition\n",
    "\n",
    "#### Workflow Steps\n",
    "\n",
    "1. Import audio segments (.wav files)\n",
    "\n",
    "2. Transcribe via google's cloud speech-to-text API\n",
    "\n",
    "3. Export results as dataframe\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "* Key for google API\n",
    "* Input path for audio files to be processed\n",
    "* Output path for csv file (the dataframe)\n",
    "* Name for said csv file\n",
    "\n",
    "Core code adapted from\n",
    "* DSI-SF-9 [(Grant Wilson, J. Hall, Gabriel Perez Prieto)](https://github.com/GWilson97/san_francisco_dispatch_audio_mapping/blob/master/code/03a_speech_to_text.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:47:56.395514Z",
     "start_time": "2020-05-13T15:47:56.391509Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade google-cloud-speech\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "from google.cloud.speech_v1p1beta1 import enums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Credentials for Google Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:47:56.863670Z",
     "start_time": "2020-05-13T15:47:56.854691Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9f9935930ff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkey_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'police-scanner-speech-to-text-c09b11750e4e.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GOOGLE_APPLICATION_CREDENTIALS\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_key\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkey_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeech\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpeechClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "path_to_key = '/Users/alex/ga-dsi-11/'\n",
    "\n",
    "key_name = 'police-scanner-speech-to-text-c09b11750e4e.json'\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = path_to_key + key_name\n",
    "\n",
    "client = speech.SpeechClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Input Path (Specific to Your Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:48:01.786450Z",
     "start_time": "2020-05-13T15:48:01.767495Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_path = '<><><><><><><><><><>'\n",
    "\n",
    "os.listdir(input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T00:24:36.025031Z",
     "start_time": "2020-05-12T00:24:36.023029Z"
    }
   },
   "source": [
    "### Establish Output Path (Specific to Your Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T19:42:11.952552Z",
     "start_time": "2020-05-13T19:42:11.945547Z"
    }
   },
   "outputs": [],
   "source": [
    "output_path = '<><><><><><><><><><>'\n",
    "\n",
    "file_name = '<><><><><><><><><><>'\n",
    "\n",
    "os.listdir(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T00:26:34.835965Z",
     "start_time": "2020-05-12T00:26:34.832957Z"
    }
   },
   "source": [
    "### Transcribe to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T18:05:13.188779Z",
     "start_time": "2020-05-13T15:51:21.784478Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for sample_audio in os.listdir(input_path):\n",
    "    loop_time = time.time()\n",
    "    \n",
    "    # Examine wav files\n",
    "    if sample_audio.endswith('.wav'):\n",
    "        \n",
    "        # Open files\n",
    "        with io.open(input_path + sample_audio,'rb') as audio_to_transcribe:\n",
    "            content = audio_to_transcribe.read()\n",
    "            audio = speech.types.RecognitionAudio(content = content)\n",
    "            \n",
    "        # Declare speech recognition parameters\n",
    "        config = speech.types.RecognitionConfig(\n",
    "            encoding = enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "            sample_rate_hertz = 22050,\n",
    "            language_code = 'en-US',\n",
    "            audio_channel_count = 1,\n",
    "            enable_separate_recognition_per_channel = True,\n",
    "            use_enhanced = True,\n",
    "            model = 'phone_call',\n",
    "            speech_contexts = [{'boost':20.0}]\n",
    "        )\n",
    "        \n",
    "        # This models equivalent of fit/predict\n",
    "        response = client.recognize(config,audio)\n",
    "        \n",
    "        # Build Dictionary that becomes a Dataframe\n",
    "        for result in response.results:\n",
    "            d = {}\n",
    "            d['transcript'] = result.alternatives[0].transcript\n",
    "            d['confidence'] = result.alternatives[0].confidence\n",
    "            d['file_name'] = sample_audio\n",
    "            d['audio_length'] = round(int(sample_audio.split(\"-\")[-1].split(\".\")[0])/1_000,1)\n",
    "            processing_time = round(time.time() - loop_time,1)\n",
    "            d['transcribe_time'] = processing_time\n",
    "            df = df.append(d, ignore_index=True)\n",
    "                    \n",
    "        print(f\"File {sample_audio} transcribed to df in {round(processing_time,0)} secs\")\n",
    "\n",
    "print(f'total time of {time.time() - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T18:05:30.341337Z",
     "start_time": "2020-05-13T18:05:30.302472Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)  \n",
    "\n",
    "df = df[['file_name',\n",
    "         'audio_length',\n",
    "         'transcribe_time',\n",
    "         'confidence',\n",
    "         'transcript']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T01:00:37.348178Z",
     "start_time": "2020-05-12T01:00:37.344188Z"
    }
   },
   "source": [
    "### Export CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T18:05:44.177905Z",
     "start_time": "2020-05-13T18:05:44.151938Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(output_path + file_name,\n",
    "          index_label = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
