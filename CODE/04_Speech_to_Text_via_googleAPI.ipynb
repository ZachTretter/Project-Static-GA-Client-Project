{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DSI BOS 11 (May 2020) Project 5\n",
    "\n",
    "Alex Golden, Jungmoon Ham, Luke Podsiadlo, Zach Tretter\n",
    "\n",
    "Workbook 4 - Speech to Text Transcription\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T19:47:09.907464Z",
     "start_time": "2020-05-13T19:47:09.903512Z"
    }
   },
   "source": [
    "## Speech Recognition\n",
    "\n",
    "#### Workflow Steps\n",
    "\n",
    "1. Import audio segments (.wav files)\n",
    "\n",
    "2. Transcribe via google's cloud speech-to-text API\n",
    "\n",
    "3. Export results as dataframe\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "* Key for google API\n",
    "* Input path for audio files to be processed\n",
    "* Output path for csv file (the dataframe)\n",
    "* Name for said csv file\n",
    "\n",
    "Core code adapted from\n",
    "* DSI-SF-9 [(Grant Wilson, J. Hall, Gabriel Perez Prieto)](https://github.com/GWilson97/san_francisco_dispatch_audio_mapping/blob/master/code/03a_speech_to_text.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:47:56.395514Z",
     "start_time": "2020-05-13T15:47:56.391509Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade google-cloud-speech\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "from google.cloud.speech_v1p1beta1 import enums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Credentials for Google Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:47:56.863670Z",
     "start_time": "2020-05-13T15:47:56.854691Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_key = '[YOUR PATH HERE]'\n",
    "\n",
    "key_name = '[YOUR KEY NAME HERE]'\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = path_to_key + key_name\n",
    "\n",
    "client = speech.SpeechClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(input_path, output_path, output_file_name):\n",
    "    start_time = time.time()\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for sample_audio in os.listdir(input_path):\n",
    "        loop_time = time.time()\n",
    "\n",
    "        # Examine wav files\n",
    "        if sample_audio.endswith('.wav'):\n",
    "\n",
    "            # Open files\n",
    "            with io.open(input_path + sample_audio,'rb') as audio_to_transcribe:\n",
    "                content = audio_to_transcribe.read()\n",
    "                audio = speech.types.RecognitionAudio(content = content)\n",
    "\n",
    "            # Declare speech recognition parameters\n",
    "            config = speech.types.RecognitionConfig(\n",
    "                encoding = enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "                sample_rate_hertz = 22050,\n",
    "                language_code = 'en-US',\n",
    "                audio_channel_count = 1,\n",
    "                enable_separate_recognition_per_channel = True,\n",
    "                use_enhanced = True,\n",
    "                model = 'phone_call',\n",
    "                speech_contexts = [{'boost':20.0}]\n",
    "            )\n",
    "\n",
    "            # This models equivalent of fit/predict\n",
    "            response = client.recognize(config,audio)\n",
    "\n",
    "            # Build Dictionary that becomes a Dataframe\n",
    "            for result in response.results:\n",
    "                d = {}\n",
    "                d['transcript'] = result.alternatives[0].transcript\n",
    "                d['confidence'] = result.alternatives[0].confidence\n",
    "                d['file_name'] = sample_audio\n",
    "                \n",
    "                processing_time = round(time.time() - loop_time,1)\n",
    "                df = df.append(d, ignore_index=True)\n",
    "                \n",
    "            df.to_csv(output_path + output_file_name, index_label = False)\n",
    "\n",
    "            print(f\"File {sample_audio} transcribed to df in {round(processing_time,0)} secs\")\n",
    "\n",
    "    print(f'total time of {time.time() - start_time}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribe_audio('../DATASETS/split_audio/split_raw/','../DATASETS/transcripts/','feed_25818_raw_transcript.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribe_audio('../DATASETS/split_audio/split_enhanced/','../DATASETS/transcripts/','feed_25818_enhanced_transcript.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)  \n",
    "\n",
    "df = df[['file_name',\n",
    "         'confidence',\n",
    "         'transcript']]\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
