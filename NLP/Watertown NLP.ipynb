{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# For Natural Language Processing\n",
    "import regex as re\n",
    "import unidecode\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watertown transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import text file, Watertown transcript\n",
    "with open('watertown.txt', 'r') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One 5'7\", the second with darker skin, both suspects armed with firearms, driving a Black Mercedes SUV.  Carjacked at 816 memorial drive at the gas station in Cambridge, Suspects are two middle eastern males, on is 5'7\", second one with\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the text by sentence\n",
    "df = data.split('\\n')\n",
    "print(df[0])\n",
    "print(df[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty sentences\n",
    "df = [string for string in df if len(string) > 0]\n",
    "\n",
    "# Put it into the dataframe\n",
    "df_transcript = pd.DataFrame({'transcript':df})\n",
    "\n",
    "# Define Watertown text as 'is_crime'\n",
    "df_transcript['type'] = 'is_crime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One 5'7\", the second with darker skin, both su...</td>\n",
       "      <td>is_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>darker skin, no description on clothing yet, a...</td>\n",
       "      <td>is_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>508, inaudible...supposedly he is saying inaud...</td>\n",
       "      <td>is_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Control:  they went into that gas station, pa...</td>\n",
       "      <td>is_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yea, I believe they have video in that Shell s...</td>\n",
       "      <td>is_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Control, the suspect vehicle is on Spruce - th...</td>\n",
       "      <td>is_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>(officer at Spruce ) 19, ahh you have a math p...</td>\n",
       "      <td>is_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>19, I don't know - I gotten word that there's ...</td>\n",
       "      <td>is_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>521, All non Cambridge units we have two suspe...</td>\n",
       "      <td>is_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>be advised ours is not in custody - he is down...</td>\n",
       "      <td>is_crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            transcript      type\n",
       "0    One 5'7\", the second with darker skin, both su...  is_crime\n",
       "1    darker skin, no description on clothing yet, a...  is_crime\n",
       "2    508, inaudible...supposedly he is saying inaud...  is_crime\n",
       "3     Control:  they went into that gas station, pa...  is_crime\n",
       "4    Yea, I believe they have video in that Shell s...  is_crime\n",
       "..                                                 ...       ...\n",
       "163  Control, the suspect vehicle is on Spruce - th...  is_crime\n",
       "164  (officer at Spruce ) 19, ahh you have a math p...  is_crime\n",
       "165  19, I don't know - I gotten word that there's ...  is_crime\n",
       "166  521, All non Cambridge units we have two suspe...  is_crime\n",
       "167  be advised ours is not in custody - he is down...  is_crime\n",
       "\n",
       "[168 rows x 2 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Football Commentary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.news18.com/fifa-world-cup-2018/commentary/21977/\n",
    "# http://www.chesterfc.com/page/3/?s=LIVE+TEXT+COMMENTARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import text file, soccer commentary transcript\n",
    "with open('football.txt', 'r') as file:\n",
    "    data2 = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text by sentence\n",
    "df_nonwatertown = data2.split('\\n')\n",
    "\n",
    "# Remove empty sentences\n",
    "df_nonwatertown = [string for string in df_nonwatertown if len(string) > 0]\n",
    "\n",
    "# Put it into the dataframe\n",
    "df_non_transcript = pd.DataFrame({'transcript':df_nonwatertown})\n",
    "\n",
    "# Define Watertown text as 'is_not_crime'\n",
    "df_non_transcript['type'] = 'is_not_crime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we played nearly six minutes yer list’ning to ...</td>\n",
       "      <td>is_not_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROBBIE SAVAGE: (2) Yeh (.) I thought united (....</td>\n",
       "      <td>is_not_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALAN GREEN: / Sergio</td>\n",
       "      <td>is_not_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROBBIE SAVAGE: /yep/</td>\n",
       "      <td>is_not_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALAN GREEN: /Ramos who got the header in</td>\n",
       "      <td>is_not_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Portugal Substitutions: Beto, Ruben Dias, Manu...</td>\n",
       "      <td>is_not_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Portugal (4-2-3-1): Rui Patricio; Cedric, Pepe...</td>\n",
       "      <td>is_not_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Spain look to repeat their 2010 World Cup perf...</td>\n",
       "      <td>is_not_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>The 2016 UEFA European Champions will look to ...</td>\n",
       "      <td>is_not_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>In what will be one of the marquee match ups i...</td>\n",
       "      <td>is_not_crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            transcript          type\n",
       "0    we played nearly six minutes yer list’ning to ...  is_not_crime\n",
       "1    ROBBIE SAVAGE: (2) Yeh (.) I thought united (....  is_not_crime\n",
       "2                                 ALAN GREEN: / Sergio  is_not_crime\n",
       "3                                 ROBBIE SAVAGE: /yep/  is_not_crime\n",
       "4             ALAN GREEN: /Ramos who got the header in  is_not_crime\n",
       "..                                                 ...           ...\n",
       "161  Portugal Substitutions: Beto, Ruben Dias, Manu...  is_not_crime\n",
       "162  Portugal (4-2-3-1): Rui Patricio; Cedric, Pepe...  is_not_crime\n",
       "163  Spain look to repeat their 2010 World Cup perf...  is_not_crime\n",
       "164  The 2016 UEFA European Champions will look to ...  is_not_crime\n",
       "165  In what will be one of the marquee match ups i...  is_not_crime\n",
       "\n",
       "[166 rows x 2 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into single dataframe\n",
    "df = pd.concat([df_transcript, df_non_transcript])\n",
    "df = df.reset_index(drop=True)\n",
    "df['is_crime'] = df['type'].map(lambda t: 1 if t == 'is_crime' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>type</th>\n",
       "      <th>is_crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One 5'7\", the second with darker skin, both su...</td>\n",
       "      <td>is_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>darker skin, no description on clothing yet, a...</td>\n",
       "      <td>is_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>508, inaudible...supposedly he is saying inaud...</td>\n",
       "      <td>is_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Control:  they went into that gas station, pa...</td>\n",
       "      <td>is_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yea, I believe they have video in that Shell s...</td>\n",
       "      <td>is_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript      type  is_crime\n",
       "0  One 5'7\", the second with darker skin, both su...  is_crime         1\n",
       "1  darker skin, no description on clothing yet, a...  is_crime         1\n",
       "2  508, inaudible...supposedly he is saying inaud...  is_crime         1\n",
       "3   Control:  they went into that gas station, pa...  is_crime         1\n",
       "4  Yea, I believe they have video in that Shell s...  is_crime         1"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.50303\n",
       "1    0.49697\n",
       "Name: is_crime, dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates and check the base accuracy\n",
    "df.drop_duplicates(inplace=True)\n",
    "df['is_crime'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def commentaries_to_words(raw_commentary):\n",
    "    \n",
    "    # Get rid of accents\n",
    "    unaccented = unidecode.unidecode(raw_commentary)\n",
    "    \n",
    "    # Get rid of punctuation\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", unaccented)\n",
    "    \n",
    "    # Get all lowercase words\n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    # Instantiate and run Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens_lem = [lemmatizer.lemmatize(i) for i in words]\n",
    "    \n",
    "    # Remove stop words\n",
    "    stops = set(stopwords.words('english'))\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    \n",
    "    # Join into string and return the result.\n",
    "    return(\" \".join(meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning the commentaries\n"
     ]
    }
   ],
   "source": [
    "# Clean all commentary \n",
    "total_commentaries = df.shape[0]\n",
    "clean_commentaries = []\n",
    "\n",
    "print(\"Cleaning the commentaries\")\n",
    "\n",
    "i = 0\n",
    "for commentary in df['transcript']:\n",
    "    clean_commentaries.append(commentaries_to_words(commentary))\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f'Commentary {i+1} of {total_commentaries}.')\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if i == total_commentaries:\n",
    "            print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>type</th>\n",
       "      <th>is_crime</th>\n",
       "      <th>clean_commentary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One 5'7\", the second with darker skin, both su...</td>\n",
       "      <td>is_crime</td>\n",
       "      <td>1</td>\n",
       "      <td>one second darker skin suspects armed firearms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>darker skin, no description on clothing yet, a...</td>\n",
       "      <td>is_crime</td>\n",
       "      <td>1</td>\n",
       "      <td>darker skin description clothing yet ahh armed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>508, inaudible...supposedly he is saying inaud...</td>\n",
       "      <td>is_crime</td>\n",
       "      <td>1</td>\n",
       "      <td>inaudible supposedly saying inaudible fled tow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Control:  they went into that gas station, pa...</td>\n",
       "      <td>is_crime</td>\n",
       "      <td>1</td>\n",
       "      <td>control went gas station paid cash gas fled to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yea, I believe they have video in that Shell s...</td>\n",
       "      <td>is_crime</td>\n",
       "      <td>1</td>\n",
       "      <td>yea believe video shell station victim believe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript      type  is_crime  \\\n",
       "0  One 5'7\", the second with darker skin, both su...  is_crime         1   \n",
       "1  darker skin, no description on clothing yet, a...  is_crime         1   \n",
       "2  508, inaudible...supposedly he is saying inaud...  is_crime         1   \n",
       "3   Control:  they went into that gas station, pa...  is_crime         1   \n",
       "4  Yea, I believe they have video in that Shell s...  is_crime         1   \n",
       "\n",
       "                                    clean_commentary  \n",
       "0  one second darker skin suspects armed firearms...  \n",
       "1  darker skin description clothing yet ahh armed...  \n",
       "2  inaudible supposedly saying inaudible fled tow...  \n",
       "3  control went gas station paid cash gas fled to...  \n",
       "4  yea believe video shell station victim believe...  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.assign(clean_commentary = clean_commentaries)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentary</th>\n",
       "      <th>crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one second darker skin suspects armed firearms...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>darker skin description clothing yet ahh armed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inaudible supposedly saying inaudible fled tow...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>control went gas station paid cash gas fled to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yea believe video shell station victim believe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          commentary  crime\n",
       "0  one second darker skin suspects armed firearms...      1\n",
       "1  darker skin description clothing yet ahh armed...      1\n",
       "2  inaudible supposedly saying inaudible fled tow...      1\n",
       "3  control went gas station paid cash gas fled to...      1\n",
       "4  yea believe video shell station victim believe...      1"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.DataFrame({'commentary': df['clean_commentary'], 'crime': df['is_crime']})\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['commentary'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# For classification modeling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    one second darker skin suspects armed firearms...\n",
       "1    darker skin description clothing yet ahh armed...\n",
       "2    inaudible supposedly saying inaudible fled tow...\n",
       "3    control went gas station paid cash gas fled to...\n",
       "4    yea believe video shell station victim believe...\n",
       "Name: commentary, dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Few examples of crime\n",
    "df.loc[df['crime']==1, 'commentary'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164    played nearly six minutes yer list ning five l...\n",
       "165    robbie savage yeh thought united know back fou...\n",
       "166                                    alan green sergio\n",
       "167                                    robbie savage yep\n",
       "168                          alan green ramos got header\n",
       "Name: commentary, dtype: object"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Few examples of not_crime\n",
    "df.loc[df['crime']==0, 'commentary'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get baseline accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.506098\n",
       "1    0.493902\n",
       "Name: crime, dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['crime'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features and target\n",
    "features = df['commentary']\n",
    "\n",
    "X = features\n",
    "y = df['crime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate CountVectorizer and add some stop words\n",
    "cv = CountVectorizer(stop_words=['inaudible','okay','portugal','spain'])\n",
    "\n",
    "# Fit the vectorizer\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_train_cv = pd.DataFrame(X_train_cv.toarray(), columns=cv.get_feature_names())\n",
    "\n",
    "# Transform the test set\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.9512195121951219\n",
      "Training accuracy: 1.0\n",
      "Testing accuracy: 0.975609756097561\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "# Fit model\n",
    "lr.fit(X_train_cv, y_train)\n",
    "\n",
    "# Get scores\n",
    "print('CV score:', cross_val_score(lr, X_train_cv, y_train, cv=3).mean())\n",
    "print('Training accuracy:', lr.score(X_train_cv, y_train))\n",
    "print('Testing accuracy:', lr.score(X_test_cv, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.9430894308943089\n",
      "Training accuracy: 0.9959349593495935\n",
      "Testing accuracy: 0.9512195121951219\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "nb = MultinomialNB(0.7)\n",
    "\n",
    "# Fit model\n",
    "nb.fit(X_train_cv, y_train)\n",
    "\n",
    "# Get scores\n",
    "print('CV score:', cross_val_score(nb, X_train_cv, y_train, cv=3).mean())\n",
    "print('Training accuracy:', nb.score(X_train_cv, y_train))\n",
    "print('Testing accuracy:', nb.score(X_test_cv, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8212244897959184"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf,X_train_cv,y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8785306122448979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'min_samples_split': 4, 'n_estimators': 25}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set model params \n",
    "rf_params = {\n",
    "    'n_estimators': [15, 20, 25],\n",
    "    'max_depth': [None, 1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2,3,4]\n",
    "}\n",
    "\n",
    "rf_gs = GridSearchCV(rf, param_grid=rf_params)\n",
    "rf_gs.fit(X_train_cv, y_train)\n",
    "print(rf_gs.best_score_)\n",
    "rf_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.926829268292683\n",
      "test score: 0.8902439024390244\n"
     ]
    }
   ],
   "source": [
    "# Store the best fit model as best_rf \n",
    "best_rf = rf_gs.best_estimator_\n",
    "\n",
    "# Evaluate the best fit model on the train and test data\n",
    "print('train score:', best_rf.score(X_train_cv, y_train))\n",
    "print('test score:', best_rf.score(X_test_cv, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best scoring model to evaluate\n",
    "predictions = lr.predict(X_test_cv)\n",
    "cm = confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted neg</th>\n",
       "      <th>predicted pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual neg</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual pos</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted neg  predicted pos\n",
       "actual neg             41              1\n",
       "actual pos              1             39"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert confusion matrix to dataframe\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                    columns = ['predicted neg', 'predicted pos'],\n",
    "                    index = ['actual neg', 'actual pos'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>confusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  predicted confusion\n",
       "109       1          1        TP\n",
       "93        1          1        TP\n",
       "52        1          1        TP"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe to show true and predicted values\n",
    "results = pd.DataFrame()\n",
    "results['actual'] = y_test\n",
    "results['predicted'] = predictions\n",
    "\n",
    "# Create column to show confusion matrix values\n",
    "results['confusion'] = ''\n",
    "\n",
    "# Set true positives\n",
    "results['confusion'] = np.where(((results['actual']==1) & (results['predicted']==1)), 'TP', results['confusion'])\n",
    "\n",
    "# Set true negatives\n",
    "results['confusion'] = np.where(((results['actual']==0) & (results['predicted']==0)), 'TN', results['confusion'])\n",
    "\n",
    "# Set false positives\n",
    "results['confusion'] = np.where(((results['actual']==0) & (results['predicted']==1)), 'FP', results['confusion'])\n",
    "\n",
    "# Set false negatives\n",
    "results['confusion'] = np.where(((results['actual']==1) & (results['predicted']==0)), 'FN', results['confusion'])\n",
    "\n",
    "results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = list(zip(cv.get_feature_names(), lr.coef_[0].T))\n",
    "coefs = pd.DataFrame(coefs, columns = ['word','coef'])\n",
    "coefs['e^coef'] = np.exp(coefs['coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coef</th>\n",
       "      <th>e^coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>spruce</td>\n",
       "      <td>0.971849</td>\n",
       "      <td>2.642827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>vehicle</td>\n",
       "      <td>0.880107</td>\n",
       "      <td>2.411157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>officer</td>\n",
       "      <td>0.771334</td>\n",
       "      <td>2.162649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>dexter</td>\n",
       "      <td>0.746303</td>\n",
       "      <td>2.109188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>watertown</td>\n",
       "      <td>0.731561</td>\n",
       "      <td>2.078322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>mt</td>\n",
       "      <td>0.682675</td>\n",
       "      <td>1.979165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>auburn</td>\n",
       "      <td>0.682675</td>\n",
       "      <td>1.979165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>copy</td>\n",
       "      <td>0.589220</td>\n",
       "      <td>1.802582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>laurel</td>\n",
       "      <td>0.576691</td>\n",
       "      <td>1.780138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>confirm</td>\n",
       "      <td>0.561408</td>\n",
       "      <td>1.753138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word      coef    e^coef\n",
       "865      spruce  0.971849  2.642827\n",
       "993     vehicle  0.880107  2.411157\n",
       "652     officer  0.771334  2.162649\n",
       "249      dexter  0.746303  2.109188\n",
       "1014  watertown  0.731561  2.078322\n",
       "621          mt  0.682675  1.979165\n",
       "72       auburn  0.682675  1.979165\n",
       "198        copy  0.589220  1.802582\n",
       "520      laurel  0.576691  1.780138\n",
       "189     confirm  0.561408  1.753138"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show words most associated with is_Crime\n",
    "coefs.sort_values(by='e^coef', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coef</th>\n",
       "      <th>e^coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>ball</td>\n",
       "      <td>-0.844388</td>\n",
       "      <td>0.429820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>get</td>\n",
       "      <td>-0.842814</td>\n",
       "      <td>0.430498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>good</td>\n",
       "      <td>-0.835097</td>\n",
       "      <td>0.433833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>time</td>\n",
       "      <td>-0.785553</td>\n",
       "      <td>0.455867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>silva</td>\n",
       "      <td>-0.777572</td>\n",
       "      <td>0.459520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>today</td>\n",
       "      <td>-0.697451</td>\n",
       "      <td>0.497852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>bruno</td>\n",
       "      <td>-0.683084</td>\n",
       "      <td>0.505057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>fernandes</td>\n",
       "      <td>-0.683084</td>\n",
       "      <td>0.505057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>ronaldo</td>\n",
       "      <td>-0.680434</td>\n",
       "      <td>0.506397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>cristiano</td>\n",
       "      <td>-0.680344</td>\n",
       "      <td>0.506443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word      coef    e^coef\n",
       "84        ball -0.844388  0.429820\n",
       "387        get -0.842814  0.430498\n",
       "408       good -0.835097  0.433833\n",
       "946       time -0.785553  0.455867\n",
       "839      silva -0.777572  0.459520\n",
       "948      today -0.697451  0.497852\n",
       "127      bruno -0.683084  0.505057\n",
       "330  fernandes -0.683084  0.505057\n",
       "789    ronaldo -0.680434  0.506397\n",
       "212  cristiano -0.680344  0.506443"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs.sort_values(by='e^coef').head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
